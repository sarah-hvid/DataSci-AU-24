{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 1 - Formulating a modeling problem\n",
    "In our first lecture, we discussed a few overarching points related to this course. Let's do a quick recap:\n",
    "- The core of this course will be devoted to exploring ways in which we can extract knowledge from data;\n",
    "- This relies on the fact that we need to be able to \"ask questions\" to our data;\n",
    "- Most of these questions will revolve around learning a mathematical or algorithmic model of relations between some features and an outcome, or, when no outcome is available, learning \"structures\" within our feature space;\n",
    "- We can do so for two (not mutually exclusive) reasons: to be able to infer the outcome from the features we can observe or to understand how and why inputs and outcomes are related;\n",
    "- Here, we will mostly focus on developing models which are **good at inferring outcomes from features** in new data.\n",
    "\n",
    "\n",
    "We emphasized that an important skill for a data scientist is that of being able to identify **questions** that can be answered with data. Let's start getting our hands dirty with this in this first class. Today, the focus will be formulating an interesting predictive questions based on a dataset of your own choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of today's exercise\n",
    "For this class, your goal is to perform the following tasks:\n",
    "1. Together with your group, choose one of these datasets (or find a new one)\n",
    "    - HippoCorpus (a dataset of recalled or imagined stories, paired with a number of story- and participant-related metadata: https://www.kaggle.com/datasets/saurabhshahane/hippocorpus)\n",
    "    - EEG Psychiatric Disorders Dataset: https://www.kaggle.com/datasets/shashwatwork/eeg-psychiatric-disorders-dataset?resource=download (from this paper: https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2021.707581/full)\n",
    "    - Personalities and random number choices from OpenPsychometrics: https://openpsychometrics.org/_rawdata/ (search for \"random numbers\")\n",
    "    - A large-scale data set containing data from a bike-sharing service and weather information: https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset.\n",
    "\n",
    "2. Load the corresponding data, which you will find under `Project Files/data` using `pandas`\n",
    "\n",
    "3. Using `pandas` and `seaborn`, get a grasp of the overall characteristics of the dataset:\n",
    "    - What is the size of your dataset, and how many features are available? \n",
    "        - Hint: Use `DataFrame.shape` from `pandas`\n",
    "    - What kind of information do the columns include?\n",
    "        - Hint: Read the dataset's documentation + associated papers. Methods like `.info()` or `.describe()` could also be useful.\n",
    "    - What *types* of variables does each of the column contain? What kind of values do we expect to find in each column?\n",
    "        - Hint: to extract this information analytically, look into `pandas` `dtype`, `unique`, and `min`/`max` functions\n",
    "        - To plot this information, use `seaborn` functions (`displot`, `pointplot`, `catplot` or `boxplot` could be helpful)\n",
    "    - What is the proportion of missing values for each column? Is there any column with a worryingly high proportion of missing values?\n",
    "        - Hint: use the `.isnull()` method and aggregate over rows using `.sum()`\n",
    "    - What is the proportion of missing values for each row? Is there any row with a worryingly high proportion of missing values?\n",
    "        - Hint: very similar to what you did above\n",
    "    - Is there any very apparent structure in your data, e.g., clusters of highly correlated features? \n",
    "        - Hint: use pandas `.corr()` and seaborn `clustermap` to look into that: https://seaborn.pydata.org/generated/seaborn.clustermap.html\n",
    "\n",
    "4. Think about what information the dataset contains, and formulate one of the following:\n",
    "    - A prediction question that can be addressed in terms of predictive performance in a regression task;\n",
    "    - A prediction question that can be addressed in terms of predictive performance in a classification task\n",
    "\n",
    "5. For the regression OR classification task you have formulated, answer the following questions:\n",
    "    - What kind of metric can you use to assess whether the model predicts successfully?\n",
    "    - What is the simplest performance baseline with no predictors you can use to assess your model's accuracy?\n",
    "    - What is the simplest performance baseline with predictors you can use to assess your model's accuracy?\n",
    "    - Can you produce some visualizations to get a sense for whether any clear pattern is emerging?\n",
    "        - Hint: you can use `seaborn` `displot`, `pointplot` or `boxplot` to visualize distributions and their summaries, `scatterplot` or `lmplot` to produce scatterplots \n",
    "        (e.g., visualizing relations between variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have done this\n",
    "1. Share your answers to 4 and 5 on the Brightspace Padlet\n",
    "2. Keep your notebooks, I will ask you to briefly run us through them!\n",
    "3. Next week, we will select a subset of your questions, and work on them for the first few weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/work/data/class_01/narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AssignmentId', 'WorkTimeInSeconds', 'WorkerId', 'annotatorAge',\n",
       "       'annotatorGender', 'annotatorRace', 'distracted', 'draining',\n",
       "       'frequency', 'importance', 'logTimeSinceEvent', 'mainEvent', 'memType',\n",
       "       'mostSurprising', 'openness', 'recAgnPairId', 'recImgPairId',\n",
       "       'similarity', 'similarityReason', 'story', 'stressful', 'summary',\n",
       "       'timeSinceEvent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
